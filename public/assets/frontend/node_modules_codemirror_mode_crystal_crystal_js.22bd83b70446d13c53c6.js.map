{"version":3,"mappings":"8JAUC,YACD,aAEAA,mCACA,gBACA,kEAGA,kBACA,0BACAC,OAGA,qCACAC,0CACAC,mBACAC,8BACAC,mDACAC,mDACAC,KACA,wEACA,+DACA,iFACA,6EACA,8FACA,yDAEAC,mCAMAC,IALA,CACA,oBACA,+CACA,aAIAC,IADA,uDAEAC,2CACAC,OACAC,eAA2C,OAC3CC,sCACAC,GACAC,oBACAC,0BACAC,sBAEAC,GAAoB,YAAY,IAAK,iBAErC,gBACA,gBACA,YAIA,oCAAoD,GACpD,yBAGA,oCAAqD,GACrD,eAAkC,KAAKlB,KAIvC,iBACA,qBACA,UAIA,MACA,cAIA,OAHAA,cAEAmB,cACAnB,WACA,OACU,iBACV,WACUM,WACVE,YACA,8EACAY,iBACAA,oBAEY,iDAGA,WACZA,eACAA,qBAJAA,iBACAA,oBAMAN,qBACAM,sBAGA,WACUb,UACV,OAGA,WAKA,cACA,oBACAc,0BAGArB,WACAA,uBACA,cAIA,cACA,YAIA,cACA,kBACAqB,wBACUrB,wBACVA,mCACA,QAEAA,WACA,YAIA,cACA,iCAIA,kBACA,IAEAsB,EAFAC,WACAC,KAGA,iBAEAD,aACAD,mBACUtB,cACVwB,KACAF,mBACUtB,cACVwB,KACAF,mBAEAA,0BACAA,WACY,0DAEZ,aACY,cAEZ,iBAIA,6BACAA,QAEAD,gBAIA,0CACAA,qBAIArB,YACAA,0FACAA,WACA,QAIAA,YACAA,WACAA,0BACUA,WACVA,oBACUA,YACVA,mBAEA,UAGAA,cACAA,iDACA,UAIAA,YACAA,WACA,YAGAA,uBACA,YAIAmB,mBAAqC,IAErCE,IADAF,OACAD,gBAIAlB,aACAA,SACA,SAGAA,SACA,MAGA,oBACA,qBACA,kBACA,mDACAsB,mBACAH,EAGA,aACA,yBACAG,iBACAA,mBACAG,KAGAA,GAIA,kBACA,qBACA,sBAAuCzB,IACvCwB,mBACAA,0CACA,QAGAD,gBACAC,mBACAA,iBACA,QAGAE,QAIA,gBACA,gBACA,YAGA,MACA,iBACA,YACA,gBAEA1B,cAGA,wBACA,MAGA,gBACA,oBACA,MAGAA,WACAA,cAEAA,mCAEAoB,iBACA,OAGA,gBACA,oBACA,MAGApB,WACAoB,iBACA,OAGA,kBACA,qBAGA,QAFAE,KAEAC,UACA,KAyBAA,SACAD,SA1BA,CACA,iBAA+B,GAC/B,mCACAF,EAGA,iBAAgC,GAChC,6BAA+C,MAC/CA,EAGA,oBAAyC,GACzC,8BAA+C,IAAK,SACpDA,EAGA,eAEA,QACA,wBACAA,EAGAE,aAOA,UAIA,gBACA,qBACA,aACAH,aACAA,YACA,wBACA,SAKA,QADAK,KACAL,UACA,KAkBAA,SACAK,SAnBA,CACA,iBAA+B,GAC/B,mCACA,SAGA,iBAAgC,GAChC,6BAA+C,MAC/C,SAGA,oBAAyC,GACzC,8BAA+C,IAAK,SACpD,SAGAA,oBAOA,gBAIA,OACAG,sBACA,OACAC,aACAC,gBACAC,eACAC,eACAC,YAIAC,oBACA,2CACAV,cAEA,yBACAH,cACAA,eAGAD,GAGAe,qBAGA,OAFAd,+CAAgE,IAEhET,qBACAwB,iCAGAA,8BAGAC,cACAC,gCACAC,mBAIAvC,yCA1aAA,CAAQwC,EAAQ","names":["d","n","F","x","S","a","k","A","T","O","Z","b","D","s","M","g","def","class","lib","v","r","e","o","i","t","u","h","w","startState","tokenize","currentIndent","lastToken","lastStyle","blocks","token","indent","y","fold","electricInput","lineComment","E"],"sources":["./node_modules/codemirror/mode/crystal/crystal.js"],"sourcesContent":["// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: https://codemirror.net/LICENSE\n\n(function(mod) {\n  if (typeof exports == \"object\" && typeof module == \"object\") // CommonJS\n    mod(require(\"../../lib/codemirror\"));\n  else if (typeof define == \"function\" && define.amd) // AMD\n    define([\"../../lib/codemirror\"], mod);\n  else // Plain browser env\n    mod(CodeMirror);\n})(function(CodeMirror) {\n  \"use strict\";\n\n  CodeMirror.defineMode(\"crystal\", function(config) {\n    function wordRegExp(words, end) {\n      return new RegExp((end ? \"\" : \"^\") + \"(?:\" + words.join(\"|\") + \")\" + (end ? \"$\" : \"\\\\b\"));\n    }\n\n    function chain(tokenize, stream, state) {\n      state.tokenize.push(tokenize);\n      return tokenize(stream, state);\n    }\n\n    var operators = /^(?:[-+/%|&^]|\\*\\*?|[<>]{2})/;\n    var conditionalOperators = /^(?:[=!]~|===|<=>|[<>=!]=?|[|&]{2}|~)/;\n    var indexingOperators = /^(?:\\[\\][?=]?)/;\n    var anotherOperators = /^(?:\\.(?:\\.{2})?|->|[?:])/;\n    var idents = /^[a-z_\\u009F-\\uFFFF][a-zA-Z0-9_\\u009F-\\uFFFF]*/;\n    var types = /^[A-Z_\\u009F-\\uFFFF][a-zA-Z0-9_\\u009F-\\uFFFF]*/;\n    var keywords = wordRegExp([\n      \"abstract\", \"alias\", \"as\", \"asm\", \"begin\", \"break\", \"case\", \"class\", \"def\", \"do\",\n      \"else\", \"elsif\", \"end\", \"ensure\", \"enum\", \"extend\", \"for\", \"fun\", \"if\",\n      \"include\", \"instance_sizeof\", \"lib\", \"macro\", \"module\", \"next\", \"of\", \"out\", \"pointerof\",\n      \"private\", \"protected\", \"rescue\", \"return\", \"require\", \"select\", \"sizeof\", \"struct\",\n      \"super\", \"then\", \"type\", \"typeof\", \"uninitialized\", \"union\", \"unless\", \"until\", \"when\", \"while\", \"with\",\n      \"yield\", \"__DIR__\", \"__END_LINE__\", \"__FILE__\", \"__LINE__\"\n    ]);\n    var atomWords = wordRegExp([\"true\", \"false\", \"nil\", \"self\"]);\n    var indentKeywordsArray = [\n      \"def\", \"fun\", \"macro\",\n      \"class\", \"module\", \"struct\", \"lib\", \"enum\", \"union\",\n      \"do\", \"for\"\n    ];\n    var indentKeywords = wordRegExp(indentKeywordsArray);\n    var indentExpressionKeywordsArray = [\"if\", \"unless\", \"case\", \"while\", \"until\", \"begin\", \"then\"];\n    var indentExpressionKeywords = wordRegExp(indentExpressionKeywordsArray);\n    var dedentKeywordsArray = [\"end\", \"else\", \"elsif\", \"rescue\", \"ensure\"];\n    var dedentKeywords = wordRegExp(dedentKeywordsArray);\n    var dedentPunctualsArray = [\"\\\\)\", \"\\\\}\", \"\\\\]\"];\n    var dedentPunctuals = new RegExp(\"^(?:\" + dedentPunctualsArray.join(\"|\") + \")$\");\n    var nextTokenizer = {\n      \"def\": tokenFollowIdent, \"fun\": tokenFollowIdent, \"macro\": tokenMacroDef,\n      \"class\": tokenFollowType, \"module\": tokenFollowType, \"struct\": tokenFollowType,\n      \"lib\": tokenFollowType, \"enum\": tokenFollowType, \"union\": tokenFollowType\n    };\n    var matching = {\"[\": \"]\", \"{\": \"}\", \"(\": \")\", \"<\": \">\"};\n\n    function tokenBase(stream, state) {\n      if (stream.eatSpace()) {\n        return null;\n      }\n\n      // Macros\n      if (state.lastToken != \"\\\\\" && stream.match(\"{%\", false)) {\n        return chain(tokenMacro(\"%\", \"%\"), stream, state);\n      }\n\n      if (state.lastToken != \"\\\\\" && stream.match(\"{{\", false)) {\n        return chain(tokenMacro(\"{\", \"}\"), stream, state);\n      }\n\n      // Comments\n      if (stream.peek() == \"#\") {\n        stream.skipToEnd();\n        return \"comment\";\n      }\n\n      // Variables and keywords\n      var matched;\n      if (stream.match(idents)) {\n        stream.eat(/[?!]/);\n\n        matched = stream.current();\n        if (stream.eat(\":\")) {\n          return \"atom\";\n        } else if (state.lastToken == \".\") {\n          return \"property\";\n        } else if (keywords.test(matched)) {\n          if (indentKeywords.test(matched)) {\n            if (!(matched == \"fun\" && state.blocks.indexOf(\"lib\") >= 0) && !(matched == \"def\" && state.lastToken == \"abstract\")) {\n              state.blocks.push(matched);\n              state.currentIndent += 1;\n            }\n          } else if ((state.lastStyle == \"operator\" || !state.lastStyle) && indentExpressionKeywords.test(matched)) {\n            state.blocks.push(matched);\n            state.currentIndent += 1;\n          } else if (matched == \"end\") {\n            state.blocks.pop();\n            state.currentIndent -= 1;\n          }\n\n          if (nextTokenizer.hasOwnProperty(matched)) {\n            state.tokenize.push(nextTokenizer[matched]);\n          }\n\n          return \"keyword\";\n        } else if (atomWords.test(matched)) {\n          return \"atom\";\n        }\n\n        return \"variable\";\n      }\n\n      // Class variables and instance variables\n      // or attributes\n      if (stream.eat(\"@\")) {\n        if (stream.peek() == \"[\") {\n          return chain(tokenNest(\"[\", \"]\", \"meta\"), stream, state);\n        }\n\n        stream.eat(\"@\");\n        stream.match(idents) || stream.match(types);\n        return \"variable-2\";\n      }\n\n      // Constants and types\n      if (stream.match(types)) {\n        return \"tag\";\n      }\n\n      // Symbols or ':' operator\n      if (stream.eat(\":\")) {\n        if (stream.eat(\"\\\"\")) {\n          return chain(tokenQuote(\"\\\"\", \"atom\", false), stream, state);\n        } else if (stream.match(idents) || stream.match(types) ||\n                   stream.match(operators) || stream.match(conditionalOperators) || stream.match(indexingOperators)) {\n          return \"atom\";\n        }\n        stream.eat(\":\");\n        return \"operator\";\n      }\n\n      // Strings\n      if (stream.eat(\"\\\"\")) {\n        return chain(tokenQuote(\"\\\"\", \"string\", true), stream, state);\n      }\n\n      // Strings or regexps or macro variables or '%' operator\n      if (stream.peek() == \"%\") {\n        var style = \"string\";\n        var embed = true;\n        var delim;\n\n        if (stream.match(\"%r\")) {\n          // Regexps\n          style = \"string-2\";\n          delim = stream.next();\n        } else if (stream.match(\"%w\")) {\n          embed = false;\n          delim = stream.next();\n        } else if (stream.match(\"%q\")) {\n          embed = false;\n          delim = stream.next();\n        } else {\n          if(delim = stream.match(/^%([^\\w\\s=])/)) {\n            delim = delim[1];\n          } else if (stream.match(/^%[a-zA-Z_\\u009F-\\uFFFF][\\w\\u009F-\\uFFFF]*/)) {\n            // Macro variables\n            return \"meta\";\n          } else if (stream.eat('%')) {\n            // '%' operator\n            return \"operator\";\n          }\n        }\n\n        if (matching.hasOwnProperty(delim)) {\n          delim = matching[delim];\n        }\n        return chain(tokenQuote(delim, style, embed), stream, state);\n      }\n\n      // Here Docs\n      if (matched = stream.match(/^<<-('?)([A-Z]\\w*)\\1/)) {\n        return chain(tokenHereDoc(matched[2], !matched[1]), stream, state)\n      }\n\n      // Characters\n      if (stream.eat(\"'\")) {\n        stream.match(/^(?:[^']|\\\\(?:[befnrtv0'\"]|[0-7]{3}|u(?:[0-9a-fA-F]{4}|\\{[0-9a-fA-F]{1,6}\\})))/);\n        stream.eat(\"'\");\n        return \"atom\";\n      }\n\n      // Numbers\n      if (stream.eat(\"0\")) {\n        if (stream.eat(\"x\")) {\n          stream.match(/^[0-9a-fA-F_]+/);\n        } else if (stream.eat(\"o\")) {\n          stream.match(/^[0-7_]+/);\n        } else if (stream.eat(\"b\")) {\n          stream.match(/^[01_]+/);\n        }\n        return \"number\";\n      }\n\n      if (stream.eat(/^\\d/)) {\n        stream.match(/^[\\d_]*(?:\\.[\\d_]+)?(?:[eE][+-]?\\d+)?/);\n        return \"number\";\n      }\n\n      // Operators\n      if (stream.match(operators)) {\n        stream.eat(\"=\"); // Operators can follow assign symbol.\n        return \"operator\";\n      }\n\n      if (stream.match(conditionalOperators) || stream.match(anotherOperators)) {\n        return \"operator\";\n      }\n\n      // Parens and braces\n      if (matched = stream.match(/[({[]/, false)) {\n        matched = matched[0];\n        return chain(tokenNest(matched, matching[matched], null), stream, state);\n      }\n\n      // Escapes\n      if (stream.eat(\"\\\\\")) {\n        stream.next();\n        return \"meta\";\n      }\n\n      stream.next();\n      return null;\n    }\n\n    function tokenNest(begin, end, style, started) {\n      return function (stream, state) {\n        if (!started && stream.match(begin)) {\n          state.tokenize[state.tokenize.length - 1] = tokenNest(begin, end, style, true);\n          state.currentIndent += 1;\n          return style;\n        }\n\n        var nextStyle = tokenBase(stream, state);\n        if (stream.current() === end) {\n          state.tokenize.pop();\n          state.currentIndent -= 1;\n          nextStyle = style;\n        }\n\n        return nextStyle;\n      };\n    }\n\n    function tokenMacro(begin, end, started) {\n      return function (stream, state) {\n        if (!started && stream.match(\"{\" + begin)) {\n          state.currentIndent += 1;\n          state.tokenize[state.tokenize.length - 1] = tokenMacro(begin, end, true);\n          return \"meta\";\n        }\n\n        if (stream.match(end + \"}\")) {\n          state.currentIndent -= 1;\n          state.tokenize.pop();\n          return \"meta\";\n        }\n\n        return tokenBase(stream, state);\n      };\n    }\n\n    function tokenMacroDef(stream, state) {\n      if (stream.eatSpace()) {\n        return null;\n      }\n\n      var matched;\n      if (matched = stream.match(idents)) {\n        if (matched == \"def\") {\n          return \"keyword\";\n        }\n        stream.eat(/[?!]/);\n      }\n\n      state.tokenize.pop();\n      return \"def\";\n    }\n\n    function tokenFollowIdent(stream, state) {\n      if (stream.eatSpace()) {\n        return null;\n      }\n\n      if (stream.match(idents)) {\n        stream.eat(/[!?]/);\n      } else {\n        stream.match(operators) || stream.match(conditionalOperators) || stream.match(indexingOperators);\n      }\n      state.tokenize.pop();\n      return \"def\";\n    }\n\n    function tokenFollowType(stream, state) {\n      if (stream.eatSpace()) {\n        return null;\n      }\n\n      stream.match(types);\n      state.tokenize.pop();\n      return \"def\";\n    }\n\n    function tokenQuote(end, style, embed) {\n      return function (stream, state) {\n        var escaped = false;\n\n        while (stream.peek()) {\n          if (!escaped) {\n            if (stream.match(\"{%\", false)) {\n              state.tokenize.push(tokenMacro(\"%\", \"%\"));\n              return style;\n            }\n\n            if (stream.match(\"{{\", false)) {\n              state.tokenize.push(tokenMacro(\"{\", \"}\"));\n              return style;\n            }\n\n            if (embed && stream.match(\"#{\", false)) {\n              state.tokenize.push(tokenNest(\"#{\", \"}\", \"meta\"));\n              return style;\n            }\n\n            var ch = stream.next();\n\n            if (ch == end) {\n              state.tokenize.pop();\n              return style;\n            }\n\n            escaped = embed && ch == \"\\\\\";\n          } else {\n            stream.next();\n            escaped = false;\n          }\n        }\n\n        return style;\n      };\n    }\n\n    function tokenHereDoc(phrase, embed) {\n      return function (stream, state) {\n        if (stream.sol()) {\n          stream.eatSpace()\n          if (stream.match(phrase)) {\n            state.tokenize.pop();\n            return \"string\";\n          }\n        }\n\n        var escaped = false;\n        while (stream.peek()) {\n          if (!escaped) {\n            if (stream.match(\"{%\", false)) {\n              state.tokenize.push(tokenMacro(\"%\", \"%\"));\n              return \"string\";\n            }\n\n            if (stream.match(\"{{\", false)) {\n              state.tokenize.push(tokenMacro(\"{\", \"}\"));\n              return \"string\";\n            }\n\n            if (embed && stream.match(\"#{\", false)) {\n              state.tokenize.push(tokenNest(\"#{\", \"}\", \"meta\"));\n              return \"string\";\n            }\n\n            escaped = embed && stream.next() == \"\\\\\";\n          } else {\n            stream.next();\n            escaped = false;\n          }\n        }\n\n        return \"string\";\n      }\n    }\n\n    return {\n      startState: function () {\n        return {\n          tokenize: [tokenBase],\n          currentIndent: 0,\n          lastToken: null,\n          lastStyle: null,\n          blocks: []\n        };\n      },\n\n      token: function (stream, state) {\n        var style = state.tokenize[state.tokenize.length - 1](stream, state);\n        var token = stream.current();\n\n        if (style && style != \"comment\") {\n          state.lastToken = token;\n          state.lastStyle = style;\n        }\n\n        return style;\n      },\n\n      indent: function (state, textAfter) {\n        textAfter = textAfter.replace(/^\\s*(?:\\{%)?\\s*|\\s*(?:%\\})?\\s*$/g, \"\");\n\n        if (dedentKeywords.test(textAfter) || dedentPunctuals.test(textAfter)) {\n          return config.indentUnit * (state.currentIndent - 1);\n        }\n\n        return config.indentUnit * state.currentIndent;\n      },\n\n      fold: \"indent\",\n      electricInput: wordRegExp(dedentPunctualsArray.concat(dedentKeywordsArray), true),\n      lineComment: '#'\n    };\n  });\n\n  CodeMirror.defineMIME(\"text/x-crystal\", \"crystal\");\n});\n"],"sourceRoot":"webpack:///","file":"node_modules_codemirror_mode_crystal_crystal_js.22bd83b70446d13c53c6.js"}